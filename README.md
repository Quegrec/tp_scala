# ğŸ” TP Spark - Analyse de Fraude Bancaire

## ğŸ“‹ Description

Ce projet implÃ©mente une analyse complÃ¨te de donnÃ©es bancaires pour la dÃ©tection de fraude, utilisant **Apache Spark** et **Scala**.

---

## ğŸ—‚ï¸ Structure du Projet

```
tp-Spark/
â”œâ”€â”€ data/                      # DonnÃ©es du TP
â”‚   â”œâ”€â”€ transactions_data.csv  # Transactions bancaires (13M lignes)
â”‚   â”œâ”€â”€ cards_data.csv         # Informations cartes
â”‚   â”œâ”€â”€ users_data.csv         # Informations clients
â”‚   â”œâ”€â”€ mcc_codes.json         # Codes catÃ©gories marchands
â”‚   â””â”€â”€ train_fraud_labels.json # Labels de fraude (rÃ©fÃ©rence)
â”‚
â”œâ”€â”€ Partie1_Exploration.scala  # Exploration et qualitÃ© des donnÃ©es
â”œâ”€â”€ Partie2_Montants.scala     # Analyse des montants et temporelle
â”œâ”€â”€ Partie3_MCC_Erreurs.scala  # Enrichissement MCC et erreurs
â”œâ”€â”€ Partie4_Fraude.scala       # Indicateurs de fraude
â”‚
â”œâ”€â”€ answer.md                  # RÃ©ponses aux questions du TP
â”œâ”€â”€ build.sbt                  # Configuration SBT
â”œâ”€â”€ .jvmopts                   # Options JVM
â””â”€â”€ README.md                  # Ce fichier
```

---

## âš™ï¸ PrÃ©requis

- **Java JDK 8** (version 32-bit ou 64-bit)
- **SBT** (Scala Build Tool) â‰¥ 1.9
- **Scala 2.13.x**
- **Apache Spark 3.5.0** (tÃ©lÃ©chargÃ© automatiquement par SBT)

### VÃ©rifier l'installation

```bash
java -version    # Doit afficher 1.8.x
sbt --version    # Doit afficher 1.9+ 
```

---

## ğŸš€ ExÃ©cution

### 1. Cloner/Ouvrir le projet

```bash
cd tp-Spark
```

### 2. Compiler le projet

```bash
sbt compile
```

### 3. ExÃ©cuter chaque partie

```bash
# Partie 1 - Exploration des donnÃ©es
sbt "runMain Partie1_Exploration"

# Partie 2 - Analyse des montants et temporelle
sbt "runMain Partie2_Montants"

# Partie 3 - Enrichissement MCC et analyse des erreurs
sbt "runMain Partie3_MCC_Erreurs"

# Partie 4 - Indicateurs de fraude et dÃ©tection
sbt "runMain Partie4_Fraude"

# Partie 5 - SynthÃ¨se finale
sbt "runMain Partie5_Synthese"
```

### 4. ExÃ©cuter tout d'un coup

```bash
# ExÃ©cuter toutes les parties sÃ©quentiellement
sbt "runMain Partie1_Exploration" && sbt "runMain Partie2_Montants" && sbt "runMain Partie3_MCC_Erreurs" && sbt "runMain Partie4_Fraude" && sbt "runMain Partie5_Synthese"
```

---

## âš ï¸ RÃ©solution des ProblÃ¨mes

### Erreur "OutOfMemoryError"

Le fichier `.jvmopts` configure la mÃ©moire JVM. Pour une JVM 32-bit :

```
-Xmx1500m
-Xms768m
```

Pour une JVM 64-bit, vous pouvez augmenter :

```
-Xmx4g
-Xms1g
```

### Erreur "Could not reserve enough space"

RÃ©duisez les valeurs dans `.jvmopts` :

```
-Xmx900m
-Xms256m
```

### Erreur "sbt server already booting"

Fermez les processus Java existants :

```bash
# Windows
taskkill /F /IM java.exe

# Linux/Mac
pkill -f java
```

### Warning "HADOOP_HOME unset"

Ce warning est normal et n'affecte pas l'exÃ©cution. Spark fonctionne sans Hadoop pour le mode local.

---

## ğŸ“Š Contenu des Parties

### Partie 1 - Exploration
- Chargement des fichiers CSV/JSON
- Affichage des schÃ©mas
- Comptage des lignes
- Identification des problÃ¨mes de types

### Partie 2 - Montants & Temporel
- Statistiques descriptives (moyenne, mÃ©diane, min, max)
- Distribution par tranches (< 10â‚¬, 10-50â‚¬, 50-200â‚¬, > 200â‚¬)
- Analyse par heure et jour de la semaine
- Identification des heures anormales

### Partie 3 - MCC & Erreurs
- Jointure avec les codes MCC
- Top catÃ©gories par volume et montant moyen
- Analyse des types d'erreurs
- Taux d'erreur par carte et client

### Partie 4 - DÃ©tection de Fraude
- CrÃ©ation d'indicateurs :
  - Transactions par carte/jour
  - Montant total par carte/jour
  - Villes diffÃ©rentes par carte
  - Ratio d'erreurs par carte
- DÃ©finition des seuils de dÃ©tection
- GÃ©nÃ©ration du DataFrame `suspicious_cards`

### Partie 5 - SynthÃ¨se
- Patterns principaux observÃ©s
- Indicateurs utiles pour un modÃ¨le ML
- Limites des donnÃ©es
- Recommandations

---

## ğŸ“ RÃ©ponses aux Questions

Toutes les rÃ©ponses aux questions du TP sont documentÃ©es dans le fichier **`answer.md`**.

---

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| Scala | 2.13.12 | Langage principal |
| Apache Spark | 3.5.0 | Traitement distribuÃ© |
| Spark SQL | 3.5.0 | RequÃªtes DataFrame |
| SBT | 1.12.0 | Build tool |

---

## ğŸ“ˆ RÃ©sultats ClÃ©s

| MÃ©trique | Valeur |
|----------|--------|
| Transactions analysÃ©es | 13 305 915 |
| Clients uniques | 1 219 |
| Cartes uniques | 4 071 |
| Taux d'erreur global | 1.59% |
| Montant mÃ©dian | 31.65 â‚¬ |
| Cartes suspectes identifiÃ©es | ~100-200 |

---

## ğŸ‘¤ Auteur

**[Nom de l'Ã©tudiant]**  
M1 TL - Janvier 2026

---

## ğŸ“„ Licence

Projet acadÃ©mique - Usage Ã©ducatif uniquement.
